<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Lab 7: Linear Regression</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>







<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">PUBH 207B: Spring 2025</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="course_schedule.html">Course Schedule</a>
</li>
<li>
  <a href="install.html">Getting Started</a>
</li>
<li>
  <a href="about.html">Assignment Guidelines</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lab Guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Lab_1.html">Lab 1</a>
    </li>
    <li>
      <a href="Lab_2.html">Lab 2</a>
    </li>
    <li>
      <a href="Lab_3.html">Lab 3</a>
    </li>
    <li>
      <a href="Lab_4.html">Lab 4</a>
    </li>
    <li>
      <a href="Lab_5.html">Lab 5</a>
    </li>
    <li>
      <a href="Lab_6.html">Lab 6</a>
    </li>
    <li>
      <a href="Lab_7.html">Lab 7</a>
    </li>
    <li>
      <a href="Lab_8.html">Lab 8</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Lab 7: Linear Regression</h1>

</div>


<p><br> <strong>Jenny Wagner, PhD, MPH</strong> <br> Department of
Public Health <br> California State University, Sacramento <br> <br></p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>As we have discussed in class, public health researchers often seek
to understand relationships between variables. Correlation and simple
linear regression are two fundamental statistical techniques used to
explore and quantify these relationships. Correlation measures the
strength and direction of the linear association between two continuous
variables, while simple linear regression goes a step further by
modeling how one variable (the dependent variable, or “outcome” of
interest) changes in response to another (the independent variable, or
“exposure” of interest). These methods are widely applied in public
health sciences, for example, to identify risk factors for disease, to
identify populations at increased risk, and ultimately to inform
decision-making.</p>
<p><strong>Correlation</strong> is used when the goal is to determine
whether two continuous variables are linearly related and to quantify
the strength and direction of that relationship. There are various
methods for calculating what is called a <em>correlation
coefficient</em>. We will use the most common method, Pearson’s
correlation coefficient (denoted by <em>r</em>). This coefficient ranges
from -1 to 1, where values close to -1 or 1 indicate a strong
relationship and values near 0 suggest little or no linear association.
Remember, of course, that correlation does not imply causation — it only
describes an association between variables.</p>
<p><strong>Simple linear regression</strong>, on the other hand, models
the relationship between an independent variable (predictor) and a
dependent variable (outcome). It not only tells us whether a
relationship exists but also provides a mathematical equation to
describe the relationship and make predictions. This method fits a
regression line to the data, represented by the equation…</p>
<p><img src="simple-linear-reg-equation.png" width="30%" style="display: block; margin: auto;" /></p>
<p>… where:</p>
<ul>
<li><em>Y</em> is the dependent variable (outcome),</li>
<li><em>X</em> is the independent variable (predictor),</li>
<li><em>β<sub>0</sub></em> is the y-intercept (i.e., the value of
<em>Y</em> when <em>X</em>=0),</li>
<li><em>β<sub>1</sub></em> is the slope (indicating how much <em>Y</em>
changes for each one-unit increase in <em>X</em>), and</li>
<li><em>ε</em> represents the error term (unexplained variation).</li>
</ul>
<p>This model can help answer questions like: What is the association
between air pollution levels and hospital admission rates for
respiratory diseases? or How does physical activity level influence
blood pressure?</p>
<p>While simple linear regression examines the effect of a single
predictor (<em>X</em>) variable on an outcome of interest,
<strong>multiple linear regression</strong> extends this concept by
incorporating two or more independent variables to explain variation in
the dependent variable. The equation for multiple linear regression
is…</p>
<p><img src="multiple-linear-reg-equation.png" width="75%" style="display: block; margin: auto;" /></p>
<p>… where each <em>X<sub>i</sub></em> represents a different predictor
variable, and each <em>β<sub>i</sub></em> is the regression coefficient
or slope associated with the corresponding predictor variable. In a
multiple regression equation, the <em>β<sub>i</sub></em> associated with
a particular predictor variable tells us how much of a change is
expected in the dependent variable with each one-unit increase in that
predictor variable, <em>holding all other predictor variables
constant</em>.</p>
<p>Multiple linear regression is particularly useful in public health
research when outcomes are influenced by multiple factors. For example,
instead of studying how exercise alone affects blood pressure, a
multiple regression model could incorporate additional variables like
diet, age, and smoking status to better explain variations in blood
pressure.</p>
<p>As we saw in our exploration of Analysis of Variance (ANOVA) last
week, linear regression too has several assumptions which must be met in
order for any conclusions we draw from a linear model to be valid.
Briefly, these assumptions are as follows:</p>
<ol style="list-style-type: decimal">
<li><strong>Linearity</strong> – The relationship between the
independent and dependent variable should be linear.</li>
<li><strong>Independence</strong> – Residuals (errors) should be
independent, meaning observations should not be influenced by one
another.</li>
<li><strong>Homoscedasticity</strong> – The variability of residuals
should be constant across all levels of the independent variable.</li>
<li><strong>Normality</strong> – The residuals should follow a normal
distribution.</li>
<li><strong>Minimal multicollinearity</strong> (for multiple regression)
– This means that predictors should not be highly correlated with one
another. In simple linear regression, there is only one predictor, so
this assumption is not relevant, but it is relevant for multiple linear
regression.</li>
</ol>
<p>In Lab 7, we will use RStudio to compute Pearson’s correlation
coefficient for several pairs of variables, fit a simple linear
regression model, and assess whether assumptions are met. We will also
briefly explore applications of multiple linear regression.</p>
<p><br></p>
</div>
<div id="objectives" class="section level1">
<h1>Objectives</h1>
<p>After completing Lab 7, you will be able to:</p>
<ol style="list-style-type: decimal">
<li>Calculate and interpret Pearson’s correlation coefficient to assess
linear relationships.</li>
<li>Perform simple and multiple linear regression.</li>
<li>Evaluate regression assumptions using diagnostic plots and
statistical checks.</li>
<li>Interpret regression results.</li>
</ol>
<p><br></p>
</div>
<div id="tasks" class="section level1">
<h1>Tasks</h1>
<p>For Lab 7, we will take a brief break from the Framingham Heart Study
and instead use the “measles_vaccination_data.csv” dataset. This is a
simulated dataset (i.e., created for example purposes) designed for
exploring the relationship between measles vaccination rates and measles
incidence across different regions, taking into account various
healthcare and population factors. It includes data for 100 regions,
with each row representing a unique region. The specific variables
include:</p>
<ul>
<li><code>RegionID</code>: A unique identifier for each region.</li>
<li><code>VaccinationRate</code>: The percentage of the population
vaccinated against measles in each region.</li>
<li><code>MeaslesIncidence</code>: The number of measles cases per
100,000 population in each region.</li>
<li><code>HealthcareAccess</code>: An index (ranging from 0 to 100)
representing the accessibility of healthcare services in each
region.</li>
<li><code>PopulationDensity</code>: The number of people per square
kilometer in each region.</li>
<li><code>PercentChildrenUnder5</code>: The percentage of the region’s
population that is under 5 years old.</li>
<li><code>SES_Category</code>: A binary indicator of area socioeconomic
status (SES), where 0=Low SES and 1=High SES.</li>
</ul>
<p><br></p>
<p>When you are ready to start Lab 7:</p>
<ol style="list-style-type: decimal">
<li>First create a new R Markdown file using the instructions on the
Assignment Guidelines page. Save this <code>.Rmd</code> file in a folder
dedicated to Lab 7 materials.</li>
<li>Next, download the file called “measles_vaccination_data.csv” from
Canvas and save it in the same folder as your Lab 7 R Markdown
file.</li>
<li>Finally, proceed to read through and carry out each of the tasks
detailed below. As usual, you will begin by loading R packages, setting
your working directory, and importing the dataset.</li>
</ol>
<p><br></p>
<div id="install-and-load-r-packages" class="section level2">
<h2>1. Install and load R packages</h2>
<p>In Lab 7, we will use functions from a couple of new packages. Copy
and paste the following into your Console (bottom-left window), then
click Return/Enter, to install the new packages:</p>
<pre><code>install.packages(c(&quot;lmtest&quot;, &quot;performance&quot;))</code></pre>
<p>After these packages have been installed, they will need to be loaded
with the <code>library()</code> function each time you start a new R
session. We will use the following packages in this Lab:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="fu">library</span>(naniar)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="fu">library</span>(stats)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="fu">library</span>(performance) </span></code></pre></div>
<p><br></p>
</div>
<div id="set-your-working-directory" class="section level2">
<h2>2. Set your working directory</h2>
<p>Set your working directory using the <code>setwd()</code> function
(see Assignment Guidelines for detailed instructions).</p>
<pre><code>setwd(&quot;YOUR FILE PATH HERE&quot;)</code></pre>
<p><br></p>
</div>
<div id="import-the-dataset-into-rstudio" class="section level2">
<h2>3. Import the dataset into RStudio</h2>
<p>Use the <code>read.csv()</code> function to import the
“measles_vaccination_data.csv” dataset. For this to work, this file will
need to be saved in the working directory you specified in the above
step.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># import dataset</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;measles_vaccination_data.csv&quot;</span>)</span></code></pre></div>
<p><br></p>
</div>
<div id="identify-and-modify-variable-types" class="section level2">
<h2>4. Identify and modify variable types</h2>
<p>In previous Labs, we have used the <code>class()</code> function to
check variable types one at a time. As a quicker alternative, we can use
the <code>str()</code> command to check the structure of our dataset,
including variable types, as follows:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># identify variable type for all variables in the dataset</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  7 variables:
##  $ VaccinationRate      : num  79.4 93.8 88.3 85 73.9 ...
##  $ HealthcareAccess     : num  79.5 93.2 88.5 81 73.5 ...
##  $ PopulationDensity    : num  815 552 619 543 276 ...
##  $ PercentChildrenUnder5: num  4.85 8.06 2.12 2.93 2.37 ...
##  $ MeaslesIncidence     : num  55.2 25.4 41.1 47.3 55.4 ...
##  $ RegionID             : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ SES_Category         : int  0 1 1 1 0 0 0 1 1 1 ...</code></pre>
<p>Our output contains a list of the variables in our dataset, followed
by the variable type, where “num” indicates a variable is numeric and
“int” indicates a variable is an integer. Most of our variables
represent quantities, so they are already formatted appropriately as
continuous numerical variables. The only variable that we may want to
modify is <code>SES_Category</code>, since the values here represent
categories (0=Low SES, 1=High SES), not quantities. We can modify this
variable as follows:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># convert SES category to unordered factor variable</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>data<span class="sc">$</span>SES_Category <span class="ot">&lt;-</span> <span class="fu">factor</span>(data<span class="sc">$</span>SES_Category, </span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>                         <span class="at">levels=</span><span class="fu">c</span>(<span class="st">&quot;0&quot;</span>, <span class="st">&quot;1&quot;</span>), </span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>                         <span class="at">ordered=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><br></p>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>5. Exploratory data analysis</h2>
<p>Since we are working with a new dataset in this Lab, we need to start
by doing some exploratory data analysis before jumping into more
in-depth analyses. We should have a good understanding of the
distribution of each variable we plan to use. For this, we may want to
generate both numerical summaries and descriptive plots. We can also
begin to explore possible relationships between variables - for example,
using scatterplots - in order to inform future analyses.</p>
<p><br></p>
<div id="a.-numerical-summaries" class="section level3">
<h3>a. Numerical summaries</h3>
<p>As we have done in previous Labs, we can use the
<code>summary()</code> function to generate a numerical summary for each
variable in our dataset, as follows:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># generate a numerical summary of all variables</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##  VaccinationRate HealthcareAccess PopulationDensity PercentChildrenUnder5
##  Min.   :70.14   Min.   :69.29    Min.   :113.9     Min.   :2.087        
##  1st Qu.:74.83   1st Qu.:75.55    1st Qu.:362.6     1st Qu.:4.083        
##  Median :81.60   Median :80.85    Median :591.3     Median :5.944        
##  Mean   :81.75   Mean   :81.75    Mean   :575.5     Mean   :5.955        
##  3rd Qu.:88.26   3rd Qu.:88.31    3rd Qu.:798.6     3rd Qu.:8.043        
##  Max.   :94.67   Max.   :96.24    Max.   :991.0     Max.   :9.924        
##  MeaslesIncidence    RegionID      SES_Category
##  Min.   :10.69    Min.   :  1.00   0:45        
##  1st Qu.:39.85    1st Qu.: 25.75   1:55        
##  Median :50.67    Median : 50.50               
##  Mean   :52.40    Mean   : 50.50               
##  3rd Qu.:66.96    3rd Qu.: 75.25               
##  Max.   :93.98    Max.   :100.00</code></pre>
<p><br></p>
</div>
<div id="b.-descriptive-plots" class="section level3">
<h3>b. Descriptive plots</h3>
<div id="examine-distributions-of-individual-variables"
class="section level4">
<h4>Examine distributions of individual variables</h4>
<p>Next, let’s visualize the distribution of each individual variable
using descriptive plots. For each continuous numerical variable, a
histogram or boxplot is an appropriate visual. For our one categorical
variable (<code>SES_Category</code>), a bar chart is most
appropriate.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># histogram of measles incidence</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="fu">hist</span>(data<span class="sc">$</span>MeaslesIncidence, <span class="at">breaks =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># histogram of vaccination rate</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="fu">hist</span>(data<span class="sc">$</span>VaccinationRate, <span class="at">breaks =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># histogram of healthcare access</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">hist</span>(data<span class="sc">$</span>HealthcareAccess, <span class="at">breaks =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># histogram of population density</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="fu">hist</span>(data<span class="sc">$</span>PopulationDensity, <span class="at">breaks =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># histogram of percent children under 5</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="fu">hist</span>(data<span class="sc">$</span>PercentChildrenUnder5, <span class="at">breaks =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># generate a simple bar chart for SES</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="fu">barplot</span>(<span class="fu">table</span>(data<span class="sc">$</span>SES_Category), </span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>        <span class="at">main =</span> <span class="st">&quot;Barchart of SES Category&quot;</span>, </span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">&quot;SES&quot;</span>, </span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">&quot;Frequency&quot;</span>, </span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>,</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>        <span class="at">names.arg =</span> <span class="fu">c</span>(<span class="st">&quot;Low SES&quot;</span>, <span class="st">&quot;High SES&quot;</span>))</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>These plots give us a good sense of the spread of each variable.
Although it is not required for linear regression that each individual
variable be normally distributed, it is still helpful to check whether
variables are heavily skewed or contain outliers, which can affect
regression results. In the event that a variable is heavily skewed, data
transformations (e.g., log transformation, square root transformation,
etc.) may help to meet linear regression assumptions or improve model
fit.</p>
<p><br></p>
</div>
<div id="explore-relationships-between-variables"
class="section level4">
<h4>Explore relationships between variables</h4>
<p>Next, we can use descriptive plots to visualize relationships between
variables. Suppose we are most interested in understanding the
relationship between measles vaccination rate and measles incidence. We
can use a scatterplot, specifying the independent (vaccination rate) and
dependent (measles incidence) variables as follows:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># scatterplot of vaccination rate and measles incidence</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="fu">plot</span>(data<span class="sc">$</span>VaccinationRate, data<span class="sc">$</span>MeaslesIncidence)</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>From the scatterplot, we see a beautiful linear relationship, where
increasing vaccination rate corresponds to decreasing measles incidence.
In other words, there is a negative linear relationship between
vaccination rate and measles incidence.</p>
<p>Particularly when we get into multiple linear regression later, we
may also be interested in the relationships between our other variables
and the outcome of interest, as well as the relationships between
predictors. If we want to examine relationships between all continuous
variables at-hand, we can generate a <strong>scatterplot matrix</strong>
using the <code>pairs()</code> function as follows:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># scatterplot matrix for all variables, excluding SES Category and Region ID</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(SES_Category, RegionID)) <span class="sc">%&gt;%</span> </span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>  <span class="fu">pairs</span>()</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-16-1.png" width="100%" /></p>
<p>You may need to expand the Plots window (click and drag at the
borders) to get a good view of all the plots. As you can imagine,
scatterplot matrices can get pretty messy if we try to use too many
variables at one time - but for a handful of variables like we have
here, they can provide an efficient way to view relationships between
each pair of variables in our dataset.</p>
<p>Here, we’ve generated a scatterplot matrix using the
<code>pairs()</code> function, <em>excluding</em>
<code>SES_Category</code> and <code>RegionID</code>, since it doesn’t
make sense to visualize these particular variables with this type of
plot. We may be interested, however, in viewing the distribution of our
outcome of interest, measles incidence, across levels of SES. We can do
this using grouped boxplots as follows:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># Boxplot of measles incidence across SES categories</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="fu">boxplot</span>(data<span class="sc">$</span>MeaslesIncidence <span class="sc">~</span> data<span class="sc">$</span>SES_Category, </span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>        <span class="at">main =</span> <span class="st">&quot;Boxplot of Measles Incidence by SES Category&quot;</span>, </span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">&quot;SES Category&quot;</span>, </span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">&quot;Measles Incidence&quot;</span>, </span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>, </span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>        <span class="at">names =</span> <span class="fu">c</span>(<span class="st">&quot;Low SES&quot;</span>, <span class="st">&quot;High SES&quot;</span>))</span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><br></p>
</div>
</div>
</div>
<div id="correlation-pearsons-r" class="section level2">
<h2>6. Correlation (Pearson’s r)</h2>
<p>After exploring relationships between variables using a scatterplot
matrix, the next step is to quantify the strength and direction of these
relationships using <strong>Pearson’s correlation coefficient</strong>
(<em>r</em>). While scatterplots provide a visual representation,
Pearson’s <em>r</em> gives us a numerical measure of how strongly two
continuous variables are linearly related, ranging from -1 (strong
negative correlation) to +1 (strong positive correlation), with 0
indicating no linear relationship. For example, the following plots show
what linear relationships might look like with different values of
Pearson’s <em>r</em>:</p>
<p><img src="correlation-plots.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br></p>
<p>Here’s a general breakdown of how to interpret values of Pearson’s
<em>r</em>:</p>
<p><img src="pearsons.png" width="75%" style="display: block; margin: auto;" /></p>
<p><br></p>
<p>Once again, suppose that we are most interested in investigating the
relationship between vaccination rate and measles incidence. The
scatterplot we generated previously suggested there is a strong negative
linear relationship between these variables. We can quantify the
strength and direction of this relationship by generating Pearson’s
<em>r</em> using the <code>cor()</code> function as follows:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="co"># generate Pearson&#39;s correlation coefficient (r) for vaccination rate and measles incidence</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="fu">cor</span>(data<span class="sc">$</span>VaccinationRate, data<span class="sc">$</span>MeaslesIncidence, <span class="at">method =</span> <span class="st">&quot;pearson&quot;</span>)</span></code></pre></div>
<pre><code>## [1] -0.9131994</code></pre>
<p>As expected, the Pearson’s correlation coefficient (-0.913) indicates
a strong negative relationship between vaccination rate and measles
incidence.</p>
<p>Just as we used a scatterplot matrix to visually examine
relationships between multiple pairs of variables, we can generate a
<strong>correlation matrix</strong> to examine Pearson’s correlation
coefficients for all possible pairs of continuous variables in the
dataset. This helps us quickly understand the direction and magnitude of
relationships between variables in our dataset and helps us identify
potential multicollinearity issues (i.e., predictors that are highly
correlated with one another) before proceeding with regression analysis.
Let’s generate a correlation matrix for all variables in our dataset
(again, excluding SES category and Region ID), as follows:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="co"># correlation matrix</span></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span> </span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(SES_Category, RegionID)) <span class="sc">%&gt;%</span> </span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>  <span class="fu">cor</span>(<span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>, <span class="at">method =</span> <span class="st">&quot;pearson&quot;</span>)</span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a><span class="fu">round</span>(cor_matrix, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                       VaccinationRate HealthcareAccess PopulationDensity
## VaccinationRate                  1.00             0.97             -0.03
## HealthcareAccess                 0.97             1.00             -0.01
## PopulationDensity               -0.03            -0.01              1.00
## PercentChildrenUnder5            0.05             0.08             -0.06
## MeaslesIncidence                -0.91            -0.89              0.34
##                       PercentChildrenUnder5 MeaslesIncidence
## VaccinationRate                        0.05            -0.91
## HealthcareAccess                       0.08            -0.89
## PopulationDensity                     -0.06             0.34
## PercentChildrenUnder5                  1.00            -0.08
## MeaslesIncidence                      -0.08             1.00</code></pre>
<p>First, a brief explanation of this code chunk:</p>
<ul>
<li><code>data %&gt;%</code>: Passes the <code>data</code> object to the
next function.</li>
<li><code>select(-c(SES_Category, RegionID))</code>: Retains all
variables except <code>SES_Category</code> and <code>RegionID</code> for
use in the subsequent function (since we only want to generate
correlation coefficients for each pair of <em>continuous</em>
variables).</li>
<li><code>cor(use = "complete.obs", method = "pearson")</code>:
<ul>
<li>The <code>cor()</code> function computes the correlation
matrix.</li>
<li>The argument <code>use = "complete.obs"</code> ensures that only
rows with complete (non-missing) data are used in the calculation. This
prevents missing values (NA) from affecting the results.</li>
<li>The <code>method = "pearson"</code> specifies the type of
correlation coefficient to compute. The default method in
<code>cor()</code> is Pearson’s correlation coefficient, but other
methods like “spearman” or “kendall” can also be specified. We just
won’t use those in this course.</li>
</ul></li>
<li><code>cor_matrix &lt;-</code>: This stores the resulting correlation
matrix as an object called <code>cor_matrix</code>. This is helpful
because then we can easily pass the correlation matrix through our next
line of code…</li>
<li><code>round(cor_matrix, 2)</code>: The <code>round()</code> function
rounds all values in the correlation matrix to two decimal places, just
to make it easier to read and interpret.</li>
</ul>
<p>Once again, the correlation matrix shows the direction and strength
of the linear relationships between different pairs of continuous
variables in our dataset. The values range from -1 to 1, where values
close to 1 indicate a strong positive correlation (both variables
increase together), while values close to -1 indicate a strong negative
correlation (one variable increases while the other decreases). Values
near 0 suggest little or no linear relationship between the
variables.</p>
<p>If we do a quick scan of our correlation matrix, we can see measles
incidence (our outcome of interest) has strong negative correlations
with vaccination rate (our main predictor of interest) and healthcare
access. Measles incidence also has a weak (but approaching moderate)
positive correlation with population density. The correlation between
measles incidence and percent children under 5 is very weak (almost 0).
Vaccination rate and healthcare access are highly correlated (we’ll keep
this in mind for later when building our multiple regression model).</p>
<p><br></p>
</div>
<div id="simple-linear-regression" class="section level2">
<h2>7. Simple linear regression</h2>
<p>Now that we have explored the relationships between variables using a
scatterplot matrix and a correlation matrix, we can move forward with
building a simple linear regression model. As discussed previously, in
this scenario we are most interested in the relationship between
vaccination rate (the independent variable, or primary “exposure” of
interest) and measles incidence (the dependent variable, or “outcome” of
interest).</p>
<p><br></p>
<div id="a.-build-the-simple-linear-model" class="section level3">
<h3>a. Build the simple linear model</h3>
<p>From our exploratory analysis above, we have already checked the
first assumption - linearity. The scatterplot of vaccination rate and
measles incidence shows a strong negative linear relationship, supported
by the Pearson’s correlation coefficient (-0.91). We will need to check
the other assumptions as well, but we first need to build the linear
model in order to do this. We can build the simple linear model using
the <code>lm()</code> function as follows:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co"># build simple linear model and save it as an object to our Environment</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(MeaslesIncidence <span class="sc">~</span> VaccinationRate, <span class="at">data =</span> data)</span></code></pre></div>
<p>We can use the <code>summary()</code> function to view the model
results as follows:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="co"># generate a summary of the regression model</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = MeaslesIncidence ~ VaccinationRate, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.1686  -5.6616   0.7829   4.2511  21.4837 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     241.1388     8.5425   28.23   &lt;2e-16 ***
## VaccinationRate  -2.3086     0.1041  -22.18   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.701 on 98 degrees of freedom
## Multiple R-squared:  0.8339, Adjusted R-squared:  0.8322 
## F-statistic: 492.1 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We’re not going to get too excited about our model results at this
stage - we still need to check the rest of the assumptions (i.e., model
diagnostics) to ensure our results are valid. For now, let’s just get
familiar with the most important components of the regression
output:</p>
<ul>
<li><strong>Coefficients</strong>: The coefficients table provides
estimates for the intercept (β<sub>0</sub>) and slope (β<sub>1</sub>) of
the simple linear regression equation, and it also indicates whether an
independent variable (in this case we only have one, vaccination rate)
is a statistically significant predictor of the dependent variable.
Specifically, we have found:
<ul>
<li><strong>β<sub>0</sub></strong> (y-intercept): The value 241.1388
means that when the vaccination rate is 0%, the predicted measles
incidence is approximately 241 cases per 100,000 population.</li>
<li><strong>β<sub>1</sub></strong> (regression coefficient for
vaccination rate): The value -2.3086 means that for every one percentage
point increase in vaccination rate, the model predicts a decrease of
about 2.3 measles cases per 100,000 population. The small p-value
associated with vaccination rate confirms that this variable is a
statistically significant predictor of measles incidence.</li>
</ul></li>
<li><strong>Adjusted R-squared</strong>: The R-squared (R<sup>2</sup>)
value represents the proportion of variance in the dependent variable
that is explained by the independent variable(s). The “adjusted”
R-squared value accounts for the number of predictors in the model and
is more reliable when comparing models with different numbers of
predictors.
<ul>
<li>In our case here, the adjusted R-squared value of 0.8322 means that
vaccination rate explains about 83% of the variance in measles
incidence, suggesting a strong model fit.</li>
</ul></li>
<li><strong>F-statistic</strong>: The F-statistic provides a measure of
overall model significance. In this case, the extremely small p-value
confirms that the model as a whole is statistically significant.</li>
</ul>
<p><br></p>
</div>
<div id="b.-model-diagnostics" class="section level3">
<h3>b. Model diagnostics</h3>
<p>Before relying on our regression results, we need to ensure that the
model meets the assumptions required for valid statistical inference.
Violations of these assumptions can lead to biased or misleading
results. In this next section, we will assess model diagnostics (i.e.,
check assumptions) by examining model <strong>residuals</strong>, which
we can use to check for homoscedasticity, normality, and potential
outliers. These checks will help confirm whether our model is
appropriate or if adjustments are needed before drawing final
conclusions.</p>
<p>Before we move on, recall that residuals represent the difference
between the <em>observed values</em> and the <em>predicted values</em>
from the regression model — they show how much the model’s predictions
deviate from the actual data points. With this in mind, let’s check each
assumption of linear regression…</p>
<p><br></p>
<div id="linearity" class="section level4">
<h4>Linearity</h4>
<p>As discussed above, we typically check the linearity assumption first
and often before we have built our linear model. The linearity
assumption simply suggests that, if linear regression is going to be an
appropriate modeling strategy, there should be a linear relationship
between the independent and dependent variables. Makes sense! As we
already confirmed there is a linear relationship between vaccination
rate and measles incidence using a scatterplot in our exploratory
analysis, we won’t run any additional diagnostics here for this
assumption.</p>
<p><br></p>
</div>
<div id="homoscedasticity" class="section level4">
<h4>Homoscedasticity</h4>
<p>To assess the assumption of homoscedasticity — which means that the
variance of residuals remains constant across all levels of the
independent variable — we can use both visual methods and statistical
tests.</p>
<p>First, we will create a <strong>residuals vs. fitted values
plot</strong>, where residuals should appear randomly scattered without
a clear pattern. If we see a funnel shape (widening or narrowing
spread), it suggests heteroscedasticity (non-constant variance). We can
create the residuals vs. fitted values plot using the
<code>plot()</code> function as follows:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a><span class="co"># generate residuals vs. fitted values plot</span></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="fu">plot</span>(model, <span class="dv">1</span>) </span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p><strong>Note:</strong> The ‘1’ in the code above refers to a specific
plot to generate from the <code>plot()</code> command, in this case, the
residuals vs. fitted values plot.</p>
<p>The residuals vs. fitted values plot looks pretty good here. The
reference line (in red) is generally straight (this is what we want to
see), and the spread of points appears generally constant as we look
from left to right.</p>
<p>Next, we will perform the <strong>Breusch-Pagan test</strong>, which
formally tests whether residual variance changes systematically. Note
that the null hypothesis of the Breusch-Pagan test is homoscedasticity
(i.e., constant variance). If we obtain a p-value less than 0.05 from
the Breusch-Pagan test, we reject the null hypothesis, which would
indicate a violation of the homoscedasticity assumption.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="co"># Breusch-Pagan test</span></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="fu">bptest</span>(model)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  model
## BP = 0.3251, df = 1, p-value = 0.5686</code></pre>
<p>In this case, our p-value is much larger than 0.05, so we can assume
homoscedasticity. Yay!</p>
<p><br></p>
</div>
<div id="normality" class="section level4">
<h4>Normality</h4>
<p>The normality assumption refers to the distribution of model
residuals. As when we checked for homoscedasticity above, we can use
both visual methods and statistical tests to check the normality
assumption.</p>
<p>Visually, we can use a Q-Q (Quantile-Quantile) plot to compare the
distribution of residuals to a theoretical normal distribution, again
using the <code>plot()</code> function as follows:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="fu">plot</span>(model, <span class="dv">2</span>) </span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p><strong>Note:</strong> The ‘2’ in the code above refers to a specific
plot to generate from the <code>plot()</code> command, in this case the
Q-Q plot.</p>
<p>The Q-Q plot here generally looks good. What we want to see is that
the points generally follow the dotted reference line and that there are
no major deviations. If the line is not perfectly straight or if there
are minor deviations toward the tails, this is okay — but any major
deviations or clear curving at the tails indicates a violation of the
normality assumption.</p>
<p>As we did in Lab 6 when checking ANOVA assumptions, we can follow up
here with the <strong>Shapiro-Wilk test</strong>. Note that the null
hypothesis of the Shapiro-Wilk test is normality. If we obtain a p-value
less than 0.05 from the Shapiro-Wilk test, we reject the null
hypothesis, which would indicate a violation of the normality
assumption.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a><span class="co"># Shapiro-Wilk test for normality of residuals</span></span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">residuals</span>(model))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(model)
## W = 0.98316, p-value = 0.2323</code></pre>
<p>In this case, our p-value is larger than 0.05, so we can assume
normality of the residuals.</p>
<p><br></p>
</div>
<div id="other-assumptions" class="section level4">
<h4>Other assumptions</h4>
<p>In this analysis, we are not going to formally test for
<strong>independence</strong> of observations using statistical methods
because this assumption is primarily determined by the study design
rather than the data itself. Independence means that each observation is
unrelated to the others — violations typically occur in time series,
clustered, or repeated measures data, which require specialized models.
Since our dataset is assumed to have independent observations, we will
proceed without additional tests. Note that we <em>can</em> use the
residuals vs. fitted values plot to give us some indication of
independence — where we expect to see no discernible pattern in the
residuals across levels of the independent variable.</p>
<p>Additionally, since we are currently using only one predictor, we do
not need to check for <strong>multicollinearity</strong> (high
correlation between independent variables). Multicollinearity becomes a
concern in multiple linear regression, where strongly correlated
predictors can distort coefficient estimates and reduce model
interpretability. We will revisit this issue in the next section on
multiple linear regression.</p>
<p><br></p>
</div>
</div>
<div id="c.-interpret-and-present-regression-results"
class="section level3">
<h3>c. Interpret and present regression results</h3>
<p>Now that we have checked the assumptions of linear regression — and
found that our model indeed meets all assumptions — we can interpret and
use the regression equation to understand the relationship between
vaccination rate and measles incidence. Let’s quickly revisit the
summary of our model:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="co"># generate a summary of the regression model</span></span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = MeaslesIncidence ~ VaccinationRate, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.1686  -5.6616   0.7829   4.2511  21.4837 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     241.1388     8.5425   28.23   &lt;2e-16 ***
## VaccinationRate  -2.3086     0.1041  -22.18   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.701 on 98 degrees of freedom
## Multiple R-squared:  0.8339, Adjusted R-squared:  0.8322 
## F-statistic: 492.1 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We can also generate a visual to accompany our results using
<code>ggplot()</code> as follows:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="co"># generate a visual to accompany model results</span></span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>data, <span class="fu">aes</span>(<span class="at">x =</span> VaccinationRate, <span class="at">y =</span> MeaslesIncidence)) <span class="sc">+</span></span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>        <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>        <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>        <span class="fu">stat_regline_equation</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>The key finding from our simple linear regression model is the
regression coefficient for vaccination rate (-2.3086), which quantifies
the relationship between vaccination coverage and measles incidence.
This coefficient tells us how much measles incidence is expected to
change for each one-unit increase in vaccination rate, which provides a
clear, numerical estimate of the protective effect of vaccination.</p>
<p>In practice, findings such as these can be used to inform public
health policies by demonstrating the impact of increasing vaccination
coverage. For example, our model shows that higher vaccination rates
significantly reduce measles incidence. Policymakers may be able to use
this evidence to advocate for expanded immunization programs, targeted
outreach in low-coverage areas, or resource allocation for vaccine
accessibility. Additionally, these results can support public health
messaging by helping communicate the importance of vaccination to
communities in an evidence-based way.</p>
<p><br></p>
</div>
</div>
<div id="multiple-linear-regression" class="section level2">
<h2>8. Multiple linear regression</h2>
<p>While our simple linear regression model provided valuable
information about the relationship between vaccination rate and measles
incidence, we know in real life that public health outcomes are often
influenced by multiple factors. To build a more comprehensive model, we
can extend our analysis to multiple linear regression, which allows us
to include additional predictor variables — such as healthcare access,
population density, socioeconomic status or demographic characteristics.
This approach helps us better understand the combined effects of
multiple factors, control for potential confounders, and improve the
accuracy of our predictions. Here, we will briefly introduce multiple
regression and examine how adding more predictors impacts our model of
measles incidence.</p>
<p><br></p>
<div id="a.-modeling-strategies" class="section level4">
<h4>a. Modeling strategies</h4>
<p>When building a multiple linear regression model, we need to
determine which predictors are most relevant to include. Our aim is to
include only the most important variables — those that meaningfully
contribute to explaining variation in the dependent variable. Including
too many predictors can lead to <em>overfitting</em>, where the model
captures random noise rather than true relationships and subsequently
makes it less generalizable to new data. An overly complex model may
also be harder to interpret and more difficult to use in practice.
Instead, we strive for a parsimonious model — one that is as simple as
possible while still capturing key relationships.</p>
<p>Two common variable selection approaches are <strong>backward
elimination</strong> and <strong>forward selection</strong>, which help
refine the model by systematically adding or removing variables based on
statistical criteria.</p>
<ul>
<li>If using backward elimination, we start with <em>all candidate
predictor variables</em> in the model. Then, we iteratively remove the
least significant predictor (based on p-values, typically using a
threshold like 0.05), one at a time, until only statistically (and
theoretically) meaningful variables remain. Under this modeling
approach, we essentially start with a comprehensive model and remove
unnecessary predictors in order to reduce complexity while maintaining
explanatory power.</li>
<li>In contrast, with forward selection, we start with <em>no
predictors</em> and gradually add variables one by one. Then, we retain
only the predictors with the strongest statistical significance at each
step. This process continues until adding more variables no longer
significantly improves the model.</li>
</ul>
<p>Both methods of variable selection help refine regression models by
balancing predictive accuracy and simplicity. Again, we want to reduce
the risk of overfitting the model while ensuring that key predictors are
included. In practice, researchers may also use <strong>stepwise
regression</strong>, which combines elements of both approaches for a
more flexible variable selection process.</p>
<p><br></p>
</div>
<div id="b.-consider-possible-confounders" class="section level4">
<h4>b. Consider possible confounders</h4>
<p>Last semester, you were introduced to the concept of confounding — a
common issue in observational research that can lead to misleading
conclusions if not properly accounted for. In public health, we often
want to understand the relationship between an exposure and an outcome,
but relationships are rarely this simple in real life. Other variables,
called confounders, can distort relationships, for example, by making
them appear stronger, weaker, or even reversing the direction.</p>
<p>A confounder is a third variable that:</p>
<ol style="list-style-type: decimal">
<li>Is associated with the predictor of interest.</li>
<li>Is independently associated with the outcome.</li>
<li>Is not on the causal pathway between the predictor and outcome.</li>
</ol>
<p>When confounding is present, failing to account for the confounder
can lead to misleading conclusions about the effect of the predictor of
interest. A common method to adjust for potential confounders is to
include them in our multiple linear regression model. By doing so, we
can estimate the effect of the predictor of interest <em>while holding
the confounder constant</em>. This allows us to isolate the predictor’s
true relationship with the outcome.</p>
<p>For example, suppose we suspect socioeconomic status might be a
confounder in the relationship between vaccination rate and measles
incidence, because:</p>
<ul>
<li>SES may influence vaccination rates (lower SES areas may have lower
vaccine coverage).</li>
<li>SES may also directly impact measles incidence (lower SES areas may
have higher disease transmission due to overcrowding or healthcare
barriers).</li>
</ul>
<p>If we fail to include SES in the model, we might incorrectly estimate
the effect of vaccination rate on measles incidence.</p>
<p><em>But how to determine whether a variable is acting as a confounder
of the relationship of interest?</em> A common approach is to compare
the regression coefficient of the predictor of interest with and without
the potential confounder in the model. If adding the suspected
confounder changes the coefficient of the predictor by more than 10%,
the variable is likely acting as a confounder. You can calculate the
percent change in the regression coefficient using the following
equation:</p>
<p><img src="confounder-calc.png" width="50%" style="display: block; margin: auto;" /></p>
<p>… where:</p>
<ul>
<li>β<sub>1</sub> is the regression coefficient corresponding to the
predictor of interest <em>without</em> the potential confounder included
in the model, and</li>
<li>β<sub>1</sub>’ is the regression coefficient corresponding to the
predictor of interest in the presence of the potential confounder.</li>
</ul>
<p>We’ll take a look at an example down below.</p>
<p><br></p>
</div>
<div id="c.-standardize-variables-if-needed" class="section level4">
<h4>c. Standardize variables if needed</h4>
<p>In lecture and in class we have discussed the concept of transforming
variables — often for the purpose of meeting model assumptions.
Transformations can also be useful in other situations, such as when
variables are on different <em>scales</em>. For example, in our dataset,
population density is measured in people per square kilometer, while
other predictors — such as vaccination rate, healthcare access, and
percent children under 5 — are in percentages (ranging from 0 to 100).
We can include these predictors in the model in their original units,
but because population density is on a much larger scale, the regression
coefficient we obtain for this variable will likely be very small and
difficult to interpret for practical purposes (if left in the original
units, the regression coefficient for population density will represent
the change in measles incidence with a <em>one-person increase</em> in
population per square kilometer). To address this issue, we can
<strong>standardize</strong> population density (it’s been a while, but
we covered this concept in Week 4), meaning we can transform this
variable into units of <em>standard deviations from the mean</em>, using
the <code>scale()</code> function as follows:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a><span class="co"># create a new variable for standardized population density</span></span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a>data<span class="sc">$</span>PopulationDensity_z <span class="ot">&lt;-</span> <span class="fu">scale</span>(data<span class="sc">$</span>PopulationDensity)</span></code></pre></div>
<p>After running the above code chunk, you should see a new variable,
called <code>PopulationDensity_z</code> included in the dataset. We’ll
use this transformed variable when building our multiple linear
regression model in the next section.</p>
<p><br></p>
</div>
<div id="d.-build-the-multiple-regression-model" class="section level4">
<h4>d. Build the multiple regression model</h4>
<p>Suppose — based on prior research and community observations — we
suspect that, in addition to vaccination rate, measles incidence also
relates to an area’s level of healthcare access, population density, and
percentage of children under 5 years old. Suppose we also suspect, for
the reasons discussed previously, that socioeconomic status may be a
potential confounder of the relationship between vaccination rate and
measles incidence. Since we already have a good sense of what the
important factors might be, let’s use backward elimination to build the
multiple regression model. This means we will start with a model
containing all predictors of interest, as follows:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a><span class="co"># start by including all predictors of interest in the model</span></span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(MeaslesIncidence <span class="sc">~</span> VaccinationRate <span class="sc">+</span> HealthcareAccess <span class="sc">+</span> </span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>               PopulationDensity_z <span class="sc">+</span> PercentChildrenUnder5 <span class="sc">+</span> SES_Category, <span class="at">data =</span> data)</span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a><span class="fu">summary</span>(model1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = MeaslesIncidence ~ VaccinationRate + HealthcareAccess + 
##     PopulationDensity_z + PercentChildrenUnder5 + SES_Category, 
##     data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.357  -3.243  -0.402   2.633  15.249 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           238.35986    6.48892  36.733  &lt; 2e-16 ***
## VaccinationRate        -1.68234    0.28153  -5.976 4.08e-08 ***
## HealthcareAccess       -0.58111    0.27666  -2.100   0.0384 *  
## PopulationDensity_z     5.96733    0.49504  12.054  &lt; 2e-16 ***
## PercentChildrenUnder5  -0.05402    0.20706  -0.261   0.7947    
## SES_Category1          -1.06899    1.22785  -0.871   0.3862    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.893 on 94 degrees of freedom
## Multiple R-squared:  0.9357, Adjusted R-squared:  0.9323 
## F-statistic: 273.6 on 5 and 94 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In Model 1, which contains all predictors of interest, we find that
vaccination rate, healthcare access, and population density
(standardized) are significant predictors of measles incidence. As
indicated by the p-value, percent children under 5 and SES category are
not significant predictors. In backward elimination, we remove the
<em>least significant</em> predictor from the model in each stage. Since
<code>PercentChildrenUnder5</code> is insignificant and has the largest
p-value, we will remove it from the next iteration of the model…</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="co"># remove least significant predictor (percent children under 5)</span></span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(MeaslesIncidence <span class="sc">~</span> VaccinationRate <span class="sc">+</span> HealthcareAccess <span class="sc">+</span> </span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>               PopulationDensity_z <span class="sc">+</span> SES_Category, <span class="at">data =</span> data)</span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a><span class="fu">summary</span>(model2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = MeaslesIncidence ~ VaccinationRate + HealthcareAccess + 
##     PopulationDensity_z + SES_Category, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.3670  -3.3579  -0.3112   2.7703  15.3943 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         238.0694     6.3613  37.425  &lt; 2e-16 ***
## VaccinationRate      -1.6722     0.2775  -6.027 3.17e-08 ***
## HealthcareAccess     -0.5914     0.2725  -2.171   0.0324 *  
## PopulationDensity_z   5.9762     0.4914  12.161  &lt; 2e-16 ***
## SES_Category1        -1.0942     1.2180  -0.898   0.3713    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.869 on 95 degrees of freedom
## Multiple R-squared:  0.9356, Adjusted R-squared:  0.9329 
## F-statistic: 345.3 on 4 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In Model 2, we find that vaccination rate, healthcare access, and
population density remain significant predictors of measles incidence.
SES Category, which we suspected could be a potential confounder, is the
only insignificant predictor, so we will remove it from the next
iteration of the model…</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a><span class="co"># remove least significant predictor (SES Category)</span></span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a>model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(MeaslesIncidence <span class="sc">~</span> VaccinationRate <span class="sc">+</span> HealthcareAccess <span class="sc">+</span> </span>
<span id="cb41-3"><a href="#cb41-3" tabindex="-1"></a>               PopulationDensity_z, <span class="at">data =</span> data)</span>
<span id="cb41-4"><a href="#cb41-4" tabindex="-1"></a><span class="fu">summary</span>(model3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = MeaslesIncidence ~ VaccinationRate + HealthcareAccess + 
##     PopulationDensity_z, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.3405  -3.2740  -0.4744   2.6706  15.6155 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         240.9973     5.4573  44.161  &lt; 2e-16 ***
## VaccinationRate      -1.7282     0.2701  -6.398 5.73e-09 ***
## HealthcareAccess     -0.5786     0.2718  -2.129   0.0358 *  
## PopulationDensity_z   5.9821     0.4909  12.186  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.864 on 96 degrees of freedom
## Multiple R-squared:  0.9351, Adjusted R-squared:  0.9331 
## F-statistic: 461.1 on 3 and 96 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>As we have now built models with and without
<code>SES_Category</code>, we can apply the formula shown previously to
determine whether this variable acts as a confounder of the relationship
between vaccination rate and measles incidence, using the regression
coefficients corresponding to vaccination rate in each model, as
follows:</p>
<p><img src="confounder-calc-example.png" width="50%" style="display: block; margin: auto;" /></p>
<p>We find that the difference in the regression coefficient for
vaccination rate in models with and without SES category is 3.24%, below
the 10% threshold. This means SES category is likely not a confounder of
the relationship between vaccination rate and measles incidence, and we
can proceed with our model excluding <code>SES_Category</code>.</p>
<p>In Model 3, all of our predictors of interest are statistically
significant. In terms of the backward elimination process, this is a
good place to stop, since all of our predictors are statistically
significant and theoretically meaningful — but this doesn’t necessarily
mean we’ve reached our final model. We still need to check for
multicollinearity, which occurs when two or more predictor variables are
highly correlated with each other.</p>
<p><br></p>
</div>
<div id="e.-identify-and-address-multicollinearity"
class="section level4">
<h4>e. Identify and address multicollinearity</h4>
<p>When predictors are strongly related, it becomes difficult to
determine their individual effects on the dependent variable. This issue
can lead to unstable coefficient estimates and inflated standard errors,
which might make some variables appear insignificant even when they are
important and reduce the reliability of our model. To address this, we
will check for multicollinearity using Variance Inflation Factor (VIF)
scores. VIF scores essentially quantify how much the variance of a
regression coefficient is inflated due to correlation with other
predictor variables, where:</p>
<ul>
<li><strong>VIF = 1</strong>: No multicollinearity (ideal
scenario).</li>
<li><strong>VIF between 1 and 5</strong>: Moderate correlation,
generally acceptable.</li>
<li><strong>VIF &gt; 5</strong>: Considerable multicollinearity, may
need further investigation.</li>
<li><strong>VIF &gt; 10</strong>: Severe multicollinearity, the
predictor should likely be removed or adjusted.</li>
</ul>
<p>Let’s compute VIF scores for each variable in our model to identify
any potential multicollinearity issues. We can do this using the
<code>check_collinearity()</code> function from the
<code>performance</code> pacakage:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="co"># generate Variance Inflation Factors for Model 2</span></span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a><span class="fu">check_collinearity</span>(model3)</span></code></pre></div>
<pre><code>## # Check for Multicollinearity
## 
## Low Correlation
## 
##                 Term  VIF        VIF 95% CI Increased SE Tolerance
##  PopulationDensity_z 1.01 [ 1.00, 3.41e+07]         1.00      0.99
##  Tolerance 95% CI
##      [0.00, 1.00]
## 
## High Correlation
## 
##              Term   VIF        VIF 95% CI Increased SE Tolerance
##   VaccinationRate 16.89 [11.88,    24.20]         4.11      0.06
##  HealthcareAccess 16.87 [11.87,    24.18]         4.11      0.06
##  Tolerance 95% CI
##      [0.04, 0.08]
##      [0.04, 0.08]</code></pre>
<p>From our output (specifically, the two leftmost columns), we can see
vaccination rate and healthcare access are listed under “High
Correlation” as they have extremely high VIF values (~16.9), meaning
these two variables are highly correlated. Since high VIF values suggest
redundant information between predictors, our model may struggle to
distinguish their individual effects — in other words, the regression
coefficients associated with these predictors may be unreliable. We have
a couple of options — (1) we can remove one of the highly correlated
predictors, or (2) we can combine the variables into an index (i.e., a
composite measure).</p>
<p>For now, let’s opt for the simpler of the two approaches — to remove
one of the highly correlated predictors. The decision for which
predictor to remove should not be made arbitrarily but rather should be
based on our theoretical understanding of the issue at-hand. In this
case, since vaccination is the <em>direct</em> intervention against
measles, and healthcare access is more indirect in that it may influence
vaccination rates, retaining vaccination rate in the model makes more
sense conceptually. So, let’s generate a new model excluding healthcare
access, as follows:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="co"># remove one predictor with high VIF</span></span>
<span id="cb45-2"><a href="#cb45-2" tabindex="-1"></a>model4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(MeaslesIncidence <span class="sc">~</span> VaccinationRate <span class="sc">+</span> PopulationDensity_z, <span class="at">data =</span> data)</span>
<span id="cb45-3"><a href="#cb45-3" tabindex="-1"></a><span class="fu">summary</span>(model4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = MeaslesIncidence ~ VaccinationRate + PopulationDensity_z, 
##     data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.5093  -3.3043  -0.3947   2.8580  15.9253 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         239.28721    5.49518   43.55   &lt;2e-16 ***
## VaccinationRate      -2.28591    0.06694  -34.15   &lt;2e-16 ***
## PopulationDensity_z   5.89126    0.49786   11.83   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.952 on 97 degrees of freedom
## Multiple R-squared:  0.932,  Adjusted R-squared:  0.9306 
## F-statistic: 665.1 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>From the output, we see that vaccination rate and population density
remain significant predictors of measles incidence. Additionally, the
adjusted R-squared remains approximately the same, at 0.9306 in Model 4,
meaning we haven’t really lost anything in terms of explained variation
in our outcome by removing healthcare access from the model.</p>
<p>Let’s double check the VIF values for Model 4:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a><span class="co"># generate Variance Inflation Factors for Model 4</span></span>
<span id="cb47-2"><a href="#cb47-2" tabindex="-1"></a><span class="fu">check_collinearity</span>(model4)</span></code></pre></div>
<pre><code>## # Check for Multicollinearity
## 
## Low Correlation
## 
##                 Term  VIF  VIF 95% CI Increased SE Tolerance Tolerance 95% CI
##      VaccinationRate 1.00 [1.00, Inf]         1.00      1.00     [0.00, 1.00]
##  PopulationDensity_z 1.00 [1.00, Inf]         1.00      1.00     [0.00, 1.00]</code></pre>
<p>We see that, after removing healthcare access from the model,
multicollinearity is no longer an issue (the VIF values are 1, meaning
no multicollinearity). Yay!</p>
<p><br></p>
</div>
<div id="f.-rerun-model-diagnostics" class="section level4">
<h4>f. Rerun model diagnostics</h4>
<p>Finally, since we have arrived at what we <em>hope</em> is our final
model, let’s quickly rerun model diagnostics to ensure our multiple
regression model still meets assumptions.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a><span class="co"># generate residuals vs. fitted values plot to assess homoscedasticity assumption</span></span>
<span id="cb49-2"><a href="#cb49-2" tabindex="-1"></a><span class="fu">plot</span>(model4, <span class="dv">1</span>) </span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>Looks good!</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a><span class="co"># generate Q-Q plot to assess normality assumption</span></span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a><span class="fu">plot</span>(model4, <span class="dv">2</span>) </span></code></pre></div>
<p><img src="Lab_7_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>Looks fine. Hooray!</p>
<p><br></p>
</div>
<div id="g.-interpret-regression-results" class="section level4">
<h4>g. Interpret regression results</h4>
<p>Our final regression model estimates the relationship between measles
incidence, vaccination rate, and population density, given by the
following equation:</p>
<p><img src="reg-equation.png" width="75%" style="display: block; margin: auto;" /></p>
<p>We can interpret our regression coefficients as follows:</p>
<ul>
<li><strong>Vaccination Rate (-2.29)</strong>: For every one percentage
point increase in vaccination coverage, measles incidence is expected to
decrease by 2.29 cases per 100,000 population, <em>holding population
density constant</em>.</li>
<li><strong>Population Density (standardized) (5.89)</strong>: For every
one-standard deviation increase in population density, measles incidence
is expected to increase by 5.89 cases per 100,000 population,
<em>holding vaccination rate constant</em>.</li>
</ul>
<p>Our results indicate that both predictors (vaccination rate and
population density) have very small p-values (&lt; 2e-16), meaning they
are highly significant contributors to the model.</p>
<p>Finally, the adjusted R-squared value of 0.9306 indicates that the
model explains about 93% of the variability in measles incidence, an
excellent fit.</p>
<p><br></p>
</div>
<div id="h.-investigate-interactions" class="section level4">
<h4>h. Investigate interactions</h4>
<p>So far in this Lab, we have assumed that each predictor variable in
our model has an independent effect on the outcome. However, in many
situations, the effect of one variable may depend on the level of
another variable — this is known as an interaction effect. We might be
interested in investigating interactions when we suspect (based on
theory or prior research) that the relationship between an independent
variable and the outcome of interest differs across levels of another
variable. For example, we found earlier in this Lab that socioeconomic
status does not act as a confounder of the relationship between
vaccination rate and measles incidence. But suppose we suspect that the
effect of vaccination rate on measles incidence <em>depends</em> on
socioeconomic status. Suppose we think that, in lower SES areas,
vaccination rates may need to be higher in order to achieve the same
reduction in measles cases (perhaps do to overcrowding, more limited
healthcare access, or other factors).</p>
<p>Building from Model 4, we can include an interaction term between
vaccination rate and SES category by putting an asterisk (*) between
these two variables, as follows:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a><span class="co"># add interaction term between vaccination rate and SES category</span></span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a>model5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(MeaslesIncidence <span class="sc">~</span> VaccinationRate<span class="sc">*</span>SES_Category <span class="sc">+</span> PopulationDensity_z, <span class="at">data =</span> data)</span>
<span id="cb51-3"><a href="#cb51-3" tabindex="-1"></a><span class="fu">summary</span>(model5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = MeaslesIncidence ~ VaccinationRate * SES_Category + 
##     PopulationDensity_z, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.9512  -3.5466  -0.5655   3.0757  15.3764 
## 
## Coefficients:
##                               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   243.4081    10.5488  23.074   &lt;2e-16 ***
## VaccinationRate                -2.3351     0.1369 -17.063   &lt;2e-16 ***
## SES_Category1                 -12.1237    13.9298  -0.870    0.386    
## PopulationDensity_z             5.9120     0.5011  11.798   &lt;2e-16 ***
## VaccinationRate:SES_Category1   0.1393     0.1730   0.805    0.423    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.971 on 95 degrees of freedom
## Multiple R-squared:  0.9329, Adjusted R-squared:  0.9301 
## F-statistic: 330.3 on 4 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note that when we include an interaction term, the <em>main
effects</em> of each variable and <em>interaction effect</em> are all
reported in the output. Based on the p-values, however, we see that the
main effect of SES category and interaction between vaccination rate and
SES category are insignificant. Womp womp. Had the interaction term been
significant, recall from lecture that:</p>
<ul>
<li>A positive (and significant) interaction coefficient suggests the
effect of one predictor variable on the outcome is increased by the
presence of the other variable.</li>
<li>A negative (and significant) interaction coefficient suggests the
effect the effect of one predictor variable on the outcome is reduced by
the presence of the other variable.</li>
</ul>
<p>Since the interaction term was insignificant and did not improve the
explanatory power of the model (based on the adjusted R<sup>2</sup>
value), best to continue with Model 4 as our final model.</p>
<p><br></p>
</div>
</div>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>In Lab 7, we have explored the use of correlation and linear
regression to analyze the relationship between vaccination rates,
population density, and measles incidence. These statistical methods are
appropriate for analyzing linear relationships when the outcome of
interest is a continuous random variable. From this Lab, we can see that
much of the work that goes into applying linear regression techniques is
in checking assumptions, or in other words, performing model
diagnostics. This is a necessary step to ensure that the results we
obtain from our linear model are valid.</p>
<p>In the next section of our course, we will discuss logistic
regression, a modeling approach used when the outcome variable is
categorical rather than continuous. This builds upon what we have
learned in linear regression but is particularly useful in public health
settings where outcomes are often binary — such as predicting whether a
disease occurs (yes/no), whether a patient is at high risk (high/low),
or whether a policy intervention succeeds or fails.</p>
<p>When you are ready, please submit the following to the Lab 7
assignment page on Canvas:</p>
<ol style="list-style-type: decimal">
<li>An R Markdown document, which has a <code>.Rmd</code> extension</li>
<li>A knitted <code>.html</code> file</li>
</ol>
<p>Please reach out to me at <a href="mailto:jenny.wagner@csus.edu"
class="email">jenny.wagner@csus.edu</a> if you have any questions. See
you in class!</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
